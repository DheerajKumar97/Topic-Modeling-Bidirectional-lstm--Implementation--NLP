{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Topic Modeling\n",
    "\n",
    "## Problem statement\n",
    "\n",
    "Researchers have access to large online archives of scientific articles. As a consequence, finding relevant articles has become more difficult. Tagging or topic modelling provides a way to give token of identification to research articles which facilitates recommendation and search process.\n",
    "\n",
    "Given the abstract and title for a set of research articles, predict the topics for each article included in the test set. \n",
    "\n",
    "Note that a research article can possibly have more than 1 topic. The research article abstracts and titles are sourced from the following 6 topics: \n",
    "\n",
    "1. Computer Science\n",
    "\n",
    "2. Physics\n",
    "\n",
    "3. Mathematics\n",
    "\n",
    "4. Statistics\n",
    "\n",
    "5. Quantitative Biology\n",
    "\n",
    "6. Quantitative Finance\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset consists of three files `train.csv`, `test.csv` and `sample_submission.csv`.\n",
    "\n",
    "|Fields| Description|\n",
    "|-------|-----------|\n",
    "|ID |Unique ID for each article|\n",
    "|TITLE|Title of the research article|\n",
    "|ABSTRACT|Abstract of the research article|\n",
    "|Computer Science|Whether article belongs to topic computer science (1/0)|\n",
    "|Physics\t|Whether article belongs to topic physics (1/0)|\n",
    "|Mathematics\t|Whether article belongs to topic Mathematics (1/0)|\n",
    "|Statistics\t|Whether article belongs to topic Statistics (1/0)|\n",
    "|Quantitative Biology\t|Whether article belongs to topic Quantitative Biology (1/0)|\n",
    "|Quantitative Finance|Whether article belongs to topic Quantitative Finance (1/0)|\n",
    "\n",
    "## Approach\n",
    "\n",
    "In this notebook, there are two approaches followed,\n",
    "1. Preprocess the text data and convert them to pad sequence\n",
    "2. Construct a **Recurrent Neural Network(RNN)** to train the dataset and predict the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "from gensim.models import Word2Vec # Word2Vec module\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, remove_stopwords, strip_numeric, stem_text\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "path1 =\"train.csv\"\n",
    "path2 =\"test.csv\"\n",
    "class DataFrame_Loader():\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        print(\"Loadind DataFrame\")\n",
    "        \n",
    "    def load_train_csv(self,path1,path2):\n",
    "        dftrain = pd.read_csv(path1)\n",
    "        dftest = pd.read_csv(path2)\n",
    "        return dftrain,dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind DataFrame\n"
     ]
    }
   ],
   "source": [
    "load= DataFrame_Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20972, 9), (8989, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df,test_df = load.load_train_csv(path1,path2)\n",
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missing values and data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                      0\n",
      "TITLE                   0\n",
      "ABSTRACT                0\n",
      "Computer Science        0\n",
      "Physics                 0\n",
      "Mathematics             0\n",
      "Statistics              0\n",
      "Quantitative Biology    0\n",
      "Quantitative Finance    0\n",
      "dtype: int64\n",
      "Index(['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics',\n",
      "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting binary column to category\n",
    "target_cols = ['Computer Science', 'Physics', 'Mathematics','Statistics', 'Quantitative Biology', 'Quantitative Finance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science  Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0                 1        0            0           0                     0   \n",
       "1                 1        0            0           0                     0   \n",
       "2                 0        0            1           0                     0   \n",
       "3                 0        0            1           0                     0   \n",
       "4                 1        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = train_df[target_cols]\n",
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot category data\n",
    "plt.figure(figsize=(10,6))\n",
    "y_data.sum(axis=0).plot.bar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data distribution is not balanced for all the classes. There are some imbalance sample data in the given training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer object\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "class DataPreprocess:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.filters = [strip_tags,\n",
    "                       strip_numeric,\n",
    "                       strip_punctuation,\n",
    "                       lambda x: x.lower(),\n",
    "                       lambda x: re.sub(r'\\s+\\w{1}\\s+', '', x),\n",
    "                       remove_stopwords]\n",
    "    def __call__(self, doc):\n",
    "        clean_words = self.__apply_filter(doc)\n",
    "        return clean_words\n",
    "    \n",
    "    def __apply_filter(self, doc):\n",
    "        try:\n",
    "            cleanse_words = set(preprocess_string(doc, self.filters))\n",
    "            return ' '.join(cleanse_words)\n",
    "        except TypeError as te:\n",
    "            raise(TypeError(\"Not a valid data {}\".format(te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccessing_Data(train,test):\n",
    "    \n",
    "    \n",
    "    feature_col = ['ID', 'TITLE', 'ABSTRACT', 'target']\n",
    "    train['target'] = 0\n",
    "    test['target'] = 1\n",
    "    combined_set = pd.concat([train[feature_col], test[feature_col]])\n",
    "    combined_set['TEXT'] = combined_set['TITLE'] + combined_set['ABSTRACT']\n",
    "    combined_set = combined_set.drop(['TITLE', 'ABSTRACT'], axis=1)\n",
    "    combined_set['Processed'] = combined_set['TEXT'].apply(DataPreprocess())\n",
    "    train_set = combined_set.loc[combined_set['target'] == 0]\n",
    "    test_set = combined_set.loc[combined_set['target'] == 1]\n",
    "    train_set = train_set.drop('target', axis=1)\n",
    "    test_set = test_set.drop('target', axis=1)\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = proccessing_Data(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps  P...</td>\n",
       "      <td>neuroimaging sampling particular markers maps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network  Rotation i...</td>\n",
       "      <td>purpose bringnew cnn named cases neural achiev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>polyharmonic particular classical study genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>approximation lifshitz magnetic existence depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>use study efficiency search machine processing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               TEXT  \\\n",
       "0   1  Reconstructing Subject-Specific Effect Maps  P...   \n",
       "1   2  Rotation Invariance Neural Network  Rotation i...   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                           Processed  \n",
       "0  neuroimaging sampling particular markers maps ...  \n",
       "1  purpose bringnew cnn named cases neural achiev...  \n",
       "2  polyharmonic particular classical study genera...  \n",
       "3  approximation lifshitz magnetic existence depe...  \n",
       "4  use study efficiency search machine processing...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>particular insights turn activation robustness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>observables laboratory dry wet distinguish fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs  Fr...</td>\n",
       "      <td>practical studies study aspects mechanisms adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "      <td>identify kmwhile turn open asfunction inside r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>increasing efficient security recently message...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                               TEXT  \\\n",
       "0  20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1  20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2  20975  Case For Static AMSDU Aggregation in WLANs  Fr...   \n",
       "3  20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
       "4  20977  Witness-Functions versus Interpretation-Functi...   \n",
       "\n",
       "                                           Processed  \n",
       "0  particular insights turn activation robustness...  \n",
       "1  observables laboratory dry wet distinguish fea...  \n",
       "2  practical studies study aspects mechanisms adv...  \n",
       "3  identify kmwhile turn open asfunction inside r...  \n",
       "4  increasing efficient security recently message...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df['Processed']\n",
    "test_data = test_df['Processed']\n",
    "\n",
    "y = y_data.values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(y_train):\n",
    "    \"\"\"\n",
    "        Encode the given list of class labels\n",
    "        :y_train_enc: returns list of encoded classes\n",
    "        :labels: actual class labels\n",
    "    \"\"\"\n",
    "    lbl_enc = LabelEncoder()\n",
    "    \n",
    "    y_train_enc = lbl_enc.fit_transform(y_train)\n",
    "    labels = lbl_enc.classes_\n",
    "    \n",
    "    return y_train_enc, labels\n",
    "\n",
    "\n",
    "def word_embedding(train, test, max_features, max_len=200):\n",
    "    try:\n",
    "        \"\"\" Keras Tokenizer class object \"\"\"\n",
    "        tokenizer = text.Tokenizer(num_words=max_features)\n",
    "        tokenizer.fit_on_texts(train)\n",
    "        \n",
    "        train_data = tokenizer.texts_to_sequences(train)\n",
    "        test_data = tokenizer.texts_to_sequences(test)\n",
    "        \n",
    "        \"\"\" Get the max_len \"\"\"\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "        \n",
    "        \"\"\" Padd the sequence based on the max-length \"\"\"\n",
    "        x_train = sequence.pad_sequences(train_data, maxlen=max_len, padding='post')\n",
    "        x_test = sequence.pad_sequences(test_data, maxlen=max_len, padding='post')\n",
    "        \"\"\" Return train, test and vocab size \"\"\"\n",
    "        return tokenizer, x_train, x_test, vocab_size\n",
    "    except ValueError as ve:\n",
    "        raise(ValueError(\"Error in word embedding {}\".format(ve)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Bidirectional lstm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 97281\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 200, 200)          19456200  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 200, 200)          800       \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 200, 512)          935936    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 225)               57825     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 225)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 168)               37968     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 148)               25012     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 148)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 95)                14155     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 95)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 64)                6144      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 34)                2210      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 34)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                1120      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 20,668,896\n",
      "Trainable params: 20,668,496\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 6000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer, x_pad_train, x_pad_valid, vocab_size = word_embedding(X_train, X_valid, max_features)\n",
    "\n",
    "x_pad_train.shape\n",
    "print(\"Vocab size: {}\".format(vocab_size))\n",
    "\n",
    "def build_rnn(vocab_size,output_dim, max_len):\n",
    "\n",
    "    model = Sequential([\n",
    "        keras.layers.Embedding(vocab_size,200,\n",
    "                              input_length=max_len),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(256,return_sequences=True)),\n",
    "        keras.layers.GlobalMaxPool1D(),\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.Dropout(0.3,activation='tanh'),\n",
    "        keras.layers.Dense(225),\n",
    "        keras.layers.Dropout(0.3,activation='tanh'),\n",
    "        keras.layers.Dense(168),\n",
    "        keras.layers.Dropout(0.2,activation='tanh'),\n",
    "        keras.layers.Dense(148),\n",
    "        keras.layers.Dropout(0.2,activation='tanh'),\n",
    "        keras.layers.Dense(95),\n",
    "        keras.layers.Dropout(0.2,activation='tanh'),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.Dropout(0.1,activation='tanh'),\n",
    "        keras.layers.Dense(34),\n",
    "        keras.layers.Dropout(0.1,activation='tanh'),\n",
    "        keras.layers.Dense(32),\n",
    "        keras.layers.Dense(output_dim, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "rnn_model = build_rnn(vocab_size, 6, max_len)\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 291s 6s/step - loss: 0.1327 - acc: 0.8507 - val_loss: 0.2595 - val_acc: 0.7824\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0333 - acc: 0.8402 - val_loss: 0.2356 - val_acc: 0.7776\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0187 - acc: 0.8634 - val_loss: 0.2547 - val_acc: 0.7517\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0168 - acc: 0.8713 - val_loss: 0.2934 - val_acc: 0.7715\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0156 - acc: 0.8647 - val_loss: 0.3559 - val_acc: 0.7807\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0144 - acc: 0.8667 - val_loss: 0.3753 - val_acc: 0.7834\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0098 - acc: 0.8769 - val_loss: 0.4153 - val_acc: 0.7561\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0096 - acc: 0.8810 - val_loss: 0.5146 - val_acc: 0.7377\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0116 - acc: 0.8842 - val_loss: 0.5581 - val_acc: 0.7010\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0181 - acc: 0.8703 - val_loss: 0.5465 - val_acc: 0.7619\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 308s 7s/step - loss: 0.0151 - acc: 0.8665 - val_loss: 0.5264 - val_acc: 0.7633\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 303s 7s/step - loss: 0.0154 - acc: 0.8724 - val_loss: 0.5358 - val_acc: 0.7449\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 303s 7s/step - loss: 0.0167 - acc: 0.8775 - val_loss: 0.5554 - val_acc: 0.7650\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 298s 6s/step - loss: 0.0193 - acc: 0.8842 - val_loss: 0.5368 - val_acc: 0.7446\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 298s 6s/step - loss: 0.0113 - acc: 0.8809 - val_loss: 0.5525 - val_acc: 0.7572\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 309s 7s/step - loss: 0.0093 - acc: 0.8776 - val_loss: 0.6298 - val_acc: 0.7197\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 301s 7s/step - loss: 0.0125 - acc: 0.8762 - val_loss: 0.6217 - val_acc: 0.7510\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 329s 7s/step - loss: 0.0147 - acc: 0.8721 - val_loss: 0.6176 - val_acc: 0.7830\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 408s 9s/step - loss: 0.0158 - acc: 0.8681 - val_loss: 0.6032 - val_acc: 0.7820\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 359s 8s/step - loss: 0.0101 - acc: 0.8654 - val_loss: 0.5812 - val_acc: 0.7330\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 584s 13s/step - loss: 0.0090 - acc: 0.8794 - val_loss: 0.6751 - val_acc: 0.7565\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 795s 17s/step - loss: 0.0153 - acc: 0.8864 - val_loss: 0.6571 - val_acc: 0.7674\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 816s 18s/step - loss: 0.0145 - acc: 0.8718 - val_loss: 0.6090 - val_acc: 0.7606\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 652s 14s/step - loss: 0.0107 - acc: 0.8782 - val_loss: 0.6327 - val_acc: 0.7704\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 326s 7s/step - loss: 0.0098 - acc: 0.8827 - val_loss: 0.6617 - val_acc: 0.7418\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 303s 7s/step - loss: 0.0094 - acc: 0.8753 - val_loss: 0.6497 - val_acc: 0.7548\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 303s 7s/step - loss: 0.0103 - acc: 0.8607 - val_loss: 0.6518 - val_acc: 0.7677\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 298s 6s/step - loss: 0.0068 - acc: 0.8707 - val_loss: 0.6409 - val_acc: 0.7663\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 301s 7s/step - loss: 0.0041 - acc: 0.8875 - val_loss: 0.6406 - val_acc: 0.7708\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 305s 7s/step - loss: 0.0060 - acc: 0.8794 - val_loss: 0.7502 - val_acc: 0.7595\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 306s 7s/step - loss: 0.0108 - acc: 0.8856 - val_loss: 0.7113 - val_acc: 0.7296\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 471s 10s/step - loss: 0.0086 - acc: 0.8701 - val_loss: 0.6591 - val_acc: 0.7616\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 609s 13s/step - loss: 0.0086 - acc: 0.8810 - val_loss: 0.6972 - val_acc: 0.7609\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 523s 11s/step - loss: 0.0064 - acc: 0.8776 - val_loss: 0.6909 - val_acc: 0.7503\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 297s 6s/step - loss: 0.0064 - acc: 0.8643 - val_loss: 0.7077 - val_acc: 0.7442\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 299s 7s/step - loss: 0.0095 - acc: 0.8682 - val_loss: 0.7487 - val_acc: 0.7684\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 416s 9s/step - loss: 0.0151 - acc: 0.8799 - val_loss: 0.6218 - val_acc: 0.7435\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 286s 6s/step - loss: 0.0089 - acc: 0.8871 - val_loss: 0.6450 - val_acc: 0.7551\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0051 - acc: 0.9071 - val_loss: 0.6860 - val_acc: 0.7595\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0036 - acc: 0.8885 - val_loss: 0.7277 - val_acc: 0.7367\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 289s 6s/step - loss: 0.0044 - acc: 0.8701 - val_loss: 0.7710 - val_acc: 0.7435\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0041 - acc: 0.8776 - val_loss: 0.7770 - val_acc: 0.7435\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0032 - acc: 0.8734 - val_loss: 0.8138 - val_acc: 0.7544\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0060 - acc: 0.8828 - val_loss: 0.7987 - val_acc: 0.7435\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 287s 6s/step - loss: 0.0047 - acc: 0.8784 - val_loss: 0.8740 - val_acc: 0.7595\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0147 - acc: 0.8856 - val_loss: 0.7165 - val_acc: 0.7463\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0137 - acc: 0.8884 - val_loss: 0.6972 - val_acc: 0.7449\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 289s 6s/step - loss: 0.0094 - acc: 0.8649 - val_loss: 0.6720 - val_acc: 0.7582\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0135 - acc: 0.8529 - val_loss: 0.6241 - val_acc: 0.7459\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 288s 6s/step - loss: 0.0064 - acc: 0.8759 - val_loss: 0.6260 - val_acc: 0.7459\n",
      "197/197 [==============================] - 58s 295ms/step - loss: 0.6368 - acc: 0.7463\n",
      "Loss:0.637 Accuracy: 0.746\n"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "history = rnn_model.fit(x_pad_train, \n",
    "                        y_train,\n",
    "                        batch_size=256,\n",
    "                       epochs=50,\n",
    "                       verbose=1,\n",
    "                       validation_split=0.2)\n",
    "\n",
    "score = rnn_model.evaluate(x_pad_valid, y_valid, verbose=1)\n",
    "\n",
    "print(\"Loss:%.3f Accuracy: %.3f\" % (score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_sequences(test_data)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test_data)\n",
    "x_pad_test = sequence.pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('sample_submission_UVKGLZE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Computer Science  Physics  Mathematics  Statistics  \\\n",
       "0  20973                 0        0            0           1   \n",
       "1  20974                 0        1            0           0   \n",
       "2  20975                 1        0            0           0   \n",
       "3  20976                 0        1            0           0   \n",
       "4  20977                 1        0            0           0   \n",
       "\n",
       "   Quantitative Biology  Quantitative Finance  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = rnn_model.predict(x_pad_test)\n",
    "\n",
    "for arr in y_preds:\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i]>0.5:\n",
    "            arr[i] = 1\n",
    "        else:\n",
    "            arr[i] = 0\n",
    "\n",
    "y_preds = y_preds.astype('int32')\n",
    "\n",
    "pred_df = pd.DataFrame(y_preds, columns=target_cols)\n",
    "\n",
    "submission_df[target_cols] = pred_df[target_cols]\n",
    "\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
